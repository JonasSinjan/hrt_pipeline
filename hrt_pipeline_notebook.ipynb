{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PHI-HRT Pipeline**\n",
    "\n",
    "_____________\n",
    "\n",
    "Author: Jonas Sinjan (MPS) <br>\n",
    "Contributor: Daniele Calchetti (MPS)\n",
    "\n",
    "Reductions Steps\n",
    "\n",
    "1. read in science data (+scaling) open path option + open for several scans at once\n",
    "2. read in flat field (+scaling)- accepts only one flat field fits file\n",
    "3. read in dark field (+scaling)\n",
    "4. apply dark field (to only science - assumes flat is dark fielded)\n",
    "5. option to clean flat field with unsharp masking (Stokes QUV, UV or V)\n",
    "6. normalise flat field\n",
    "7. apply flat field\n",
    "8. prefilter correction\n",
    "9. apply field stop\n",
    "10. demodulate with const demod matrix\n",
    "11. normalise to quiet sun\n",
    "12. I -> Q,U,V cross talk correction\n",
    "13. rte inversion with cmilos\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download files\n",
    "\n",
    "(This requires the hrt_pipeline_env environment - or the correct modules installed with pip (see `requirements.txt`)\n",
    "\n",
    "Options:\n",
    "\n",
    "1. Can download manually yourself from the PHI Image Database: https://www2.mps.mpg.de/services/proton/phi/imgdb/\n",
    "\n",
    "    Suggested filters on the database for HRT science data: \n",
    "    - KEYWORD DETECTOR = 'HRT' <br >\n",
    "    - Filename\\* like \\*L1_phi-hrt-ilam_date\\*\n",
    "    \n",
    "   Once you find the file you want use the Command Line: \n",
    "    \n",
    "    ```\n",
    "    wget --user yourusername --password yourpassword file_web_address_from_database\n",
    "    gunzip file.gz\n",
    "    ```\n",
    "       \n",
    "2. Use the provided script in 'downloads' folder (**Benefit: can download multiple files at once**): `downloads/download_from_db.py`\n",
    "\n",
    "    Instructions:\n",
    "  1. From the database find the files you wish to download\n",
    "  2. Copy the 'Download File List' that the database will generate\n",
    "  3. Paste into the `downloads/file_names.txt` file\n",
    "  4. Create a `downloads/.env` file with your MPS Windows login: <br> \n",
    "      ```text=\n",
    "      USER_NAME =\n",
    "      PHIDATAPASSWORD =\n",
    "      ```  \n",
    "  5. Set the **target download folder** in the `download_from_db.py` file\n",
    "  6. Run the file (will require dotenv python module to be installed - included in `hrt_pipeline_env`):\n",
    "      ```text=\n",
    "      python download_from_db.py\n",
    "      ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Input JSON (config) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#example\n",
    "\n",
    "data_path = ['data_one.fits', 'data_two.fits', 'etc.fits...'] \n",
    "\n",
    "#can have as many files as you like, contintue the list\n",
    "\n",
    "\"\"\"\n",
    "IMPORTANT\n",
    "\n",
    "- files will be procssed with the same flat, dark\n",
    "- must have the same continuum position, pmp temp etc - checks will be run, and pipeline will exit if they fail\n",
    "- if data is a limb image, the limb in the FOV must be known - ie N, S, E, W etc. before processing\n",
    "\"\"\"\n",
    "\n",
    "dir_data_path = '/path/to/your/data/folder'\n",
    "data = [dir_data_path + i for i in data_path]\n",
    "\n",
    "flat_path = '/path/to/your/flat.fits'\n",
    "dark_path = '/path/to/your/dark.fits'\n",
    "\n",
    "input_dict = {\n",
    "\n",
    "    #input data\n",
    "    'data_f' : data,                            #hrt pipeline allows multiple files at once to be processed \n",
    "    'flat_f' : flat_path,\n",
    "    'dark_f' : dark_path,\n",
    "    \n",
    "    #input/output type + scaling\n",
    "    'L1_input' : False,                         #ignore - in development\n",
    "    'L1_8_generate': False,                     #ignore - in development\n",
    "    'scale_data' : True,                        #leave as True if L1 data\n",
    "    'accum_scaling' : True,                     #leave as True if L1 data\n",
    "    'bit_conversion' : True,                    #leave as True if L1 data\n",
    "    \n",
    "    #reduction\n",
    "    'dark_c' : True,                            #apply dark field correction\n",
    "    'flat_c' : True,                            #apply flat field correction\n",
    "    'norm_f' : True,                            #normalise the flats before used (DEFAULT: True)\n",
    "    'clean_f' : True,                           #clean the flat fields with unsharp masking\n",
    "    'sigma' : 59,                               #unsharp masking gaussian width\n",
    "    'clean_mode' : \"V\",                         #options 'QUV', 'UV', 'V' for the unsharp masking\n",
    "    'flat_states' : 24,                         #options 24 (DEFAULT), 4 (one each pol state), 6 (one each wavelength), \n",
    "    'prefilter_f': None,                        #provide the path for the prefilter .fits file\n",
    "    'fs_c' : True,                              #apply the field stop\n",
    "    'iss_off': False,                           #If iss switched off, set this to True, will coalign images - STRONGLY recomended to also then set VtoQU to True\n",
    "    'demod' : True,                             #demodulate to create the stokes maps\n",
    "    'norm_stokes' : True,                       #normalise the stokes maps to I_continuum\n",
    "    'ItoQUV' : True,                            #apply I-> Q,U,V cross talk correction\n",
    "    'VtoQU' : False,                            #apply V-> Q,U cross talk correction\n",
    "    'ghost_c' : False,                          #if True, excludes ghost region for ItoQUV ctalk calculation \n",
    "    'rte' : False,                              #options: RTE', 'CE' (classical estimates), 'CE+RTE'\n",
    "    'p_milos' : False,                          #DO NOT USE\n",
    "    'cmilos_fits': False,                       #use cmilos with .fits IO - 16% speed up - but not calibrated with default CMILOS\n",
    "    \n",
    "    #output dir/filenames\n",
    "    'out_dir' : None,                           #directory where you want the output files to go (string)\n",
    "    'out_stokes_file' : False,                  #if True, will save the final stokes array to fits file(s)\n",
    "    'out_stokes_filename' : None,               #if specific required otherwise will default to standard convention\n",
    "    'out_rte_filename' : None,                  #if specific required otherwise will default to standard convention\n",
    "    'config' : True,                            #if True, saves a copy of the input file with runtime in the output folder\n",
    "    'out_intermediate': False,                  #if True, save intermediate steps to fits files in the output folder (OUT_STOKES_FILE MUST BE SET TO TRUE)\n",
    "    'vers': \"01\",                               #desired version number, only 2 characters 01 -> 99, if not specified, '01' default\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "\n",
    "#      CHANGE NAME OF CONFIG FILE + CREATE\n",
    "\n",
    "##################################################################\n",
    "\n",
    "#json.dump(input_dict, open(f\"./input_jsons/name_your_input_file.json\", \"w\")) #uncomment to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Run the Pipeline\n",
    "\n",
    "Two options\n",
    "1. Run within notebook <br>\n",
    "2. Run in Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "PHI HRT data reduction software   \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Reading Data\n",
      "Input contains 1 scan(s)\n",
      "Dividing by number of accumulations: 20\n",
      "Continuum position at wave:  0\n",
      "This scan has been flipped in the Y axis to conform to orientation standards. \n",
      " File: /data/slam/home/sinjan/fits_files/solo_L1_phi-hrt-ilam_20210914T071515_V202110260809C_0149140401.fits\n",
      "All the scan(s) have the same dimension\n",
      "All the scan(s) have the same continuum wavelength position\n",
      "All the scan(s) have the same PMP Temperature Set Point: 50\n",
      "Data shape is (2048, 2048, 24, 1)\n",
      "All the scan(s) have the same IMGDIRX keyword: YES\n",
      "Data reshaped to:  (2048, 2048, 4, 6, 1)\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------ Load science data time: 0.589 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Reading Flats\n",
      "Dividing by number of accumulations: 150\n",
      "Flat field shape is (24, 2048, 2048)\n",
      "(2048, 2048, 4, 6)\n",
      "Continuum position at wave:  5\n",
      "The continuum position of the flat field is at 5 index position\n",
      "The flat field continuum position is not the same as the data, trying to correct.\n",
      "Flat PMP Temperature Set Point: 50\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------ Load flats time: 0.615 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Reading Darks                   \n",
      "Dividing by number of accumulations: 20\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------ Load darks time: 0.035 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Subtracting dark field\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------- Dark Field correction time: 0.068 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> No clean flats mode\n",
      " \u001b[0m\n",
      "-->>>>>>> Normalising Flats\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------- Normalising flat time: 0.079 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Correcting Flatfield\n",
      "Dividing by 24 flats, one for each image\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------- Flat Field correction time: 0.356 seconds  \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> No prefilter mode\n",
      " \u001b[0m\n",
      "-->>>>>>> Applying field stop\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------- Field stop time: 0.252 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Demodulating data\n",
      "Using a constant demodulation matrix for a PMP TEMP of 50 deg\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------- Demodulation time: 1.819 seconds  \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Normalising Stokes to Quiet Sun\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------- Stokes Normalising time: 1.706 seconds  \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Cross-talk correction I to Q,U,V \n",
      "  ---- >>>>> CT parameters computation of data scan number: 0 .... \n",
      "Cross-talk from I to Q: slope =  -0.0030 ; off-set =  -0.0012 \n",
      "Cross-talk from I to U: slope =  -0.0031 ; off-set =  -0.0008 \n",
      "Cross-talk from I to V: slope =  -0.0025 ; off-set =  -0.0001 \n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------- I -> Q,U,V cross talk correction time: 4.084 seconds  \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "Saving demodulated data to one 'stokes' file per scan\n",
      "The scans' DIDs are all unique\n",
      "Writing out stokes file as: solo_L2_phi-hrt-stokes_20210914T071515_V02_0149140401.fits\n",
      " \n",
      "-->>>>>>> RUNNING PMILOS \n",
      "Pmilos executable located at: /scratch/slam/sinjan/solo_attic_fits/hrt_pipeline/p-milos/\n",
      "It is assumed the wavelength array is given by the hdr\n",
      "Wave axis is:  [-296.1459 -137.007   -67.0983    0.       70.6113  139.4661]\n",
      "Saving data into ./p-milos/run/data/input_tmp.fits for pmilos RTE input\n",
      "[6173.0392541 6173.198393  6173.2683017 6173.3354    6173.4060113\n",
      " 6173.4748661]\n",
      "  ---- >>>>> Inverting data scan number: 0 .... \n",
      "(2048, 2048, 13)\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------- PMILOS RTE Run Time: 32.692 seconds  \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "--------------------------------------------------------------\n",
      "------------ Reduction Complete: 44.921 seconds\n",
      "--------------------------------------------------------------\n",
      "\u001b\u001b[0m\r"
     ]
    }
   ],
   "source": [
    "#Example RUN the pipe\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#make sure the 'sophi_hrt_pipe' package is installed in your environment:\n",
    "# 'pip install .' or 'conda develop .'\n",
    "\n",
    "from sophi_hrt_pipe.hrt_pipe import phihrt_pipe\n",
    "\n",
    "#insert name of your input file\n",
    "\n",
    "stokes = phihrt_pipe('./input_jsons/name_of_your_input_file.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or can run in terminal (either through jupyter or yourself):\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd + './src/sophi_hrt_pipe/')\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "#       CHANGE INPUT FILE LOC IN 'phihrt_pipe' function in 'run.py'\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "!python run.py\n",
    "\n",
    "os.chdir(cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrt_pipeline_env",
   "language": "python",
   "name": "hrt_pipeline_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
