{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PHI-HRT Pipeline**\n",
    "\n",
    "_____________\n",
    "\n",
    "Author: Jonas Sinjan (MPS) <br>\n",
    "Contributor: Daniele Calchetti (MPS)\n",
    "\n",
    "Reductions Steps\n",
    "\n",
    "1. read in science data (+scaling) open path option + open for several scans at once\n",
    "2. read in flat field (+scaling)- accepts only one flat field fits file\n",
    "3. read in dark field (+scaling)\n",
    "4. apply dark field (to only science - assumes flat is dark fielded)\n",
    "5. option to clean flat field with unsharp masking (Stokes QUV, UV or V)\n",
    "6. normalise flat field\n",
    "7. apply flat field\n",
    "8. prefilter correction\n",
    "9. apply field stop\n",
    "10. demodulate with const demod matrix\n",
    "11. normalise to quiet sun\n",
    "12. I -> Q,U,V cross talk correction\n",
    "13. rte inversion with cmilos\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download files\n",
    "\n",
    "(This requires the hrt_pipeline_env environment - or the correct modules installed with pip (see `requirements.txt`)\n",
    "\n",
    "Options:\n",
    "\n",
    "1. Can download manually yourself from the PHI Image Database: https://www2.mps.mpg.de/services/proton/phi/imgdb/\n",
    "\n",
    "    Suggested filters on the database for HRT science data: \n",
    "    - KEYWORD DETECTOR = 'HRT' <br >\n",
    "    - Filename\\* like \\*L1_phi-hrt-ilam_date\\*\n",
    "    \n",
    "   Once you find the file you want use the Command Line: \n",
    "    \n",
    "    ```\n",
    "    wget --user yourusername --password yourpassword file_web_address_from_database\n",
    "    gunzip file.gz\n",
    "    ```\n",
    "       \n",
    "2. Use the provided script in 'downloads' folder (**Benefit: can download multiple files at once**): `downloads/download_from_db.py`\n",
    "\n",
    "    Instructions:\n",
    "  1. From the database find the files you wish to download\n",
    "  2. Copy the 'Download File List' that the database will generate\n",
    "  3. Paste into the `downloads/file_names.txt` file\n",
    "  4. Create a `downloads/.env` file with your MPS Windows login: <br> \n",
    "      ```text=\n",
    "      USER_NAME =\n",
    "      PHIDATAPASSWORD =\n",
    "      ```  \n",
    "  5. Set the **target download folder** in the `download_from_db.py` file\n",
    "  6. Run the file (will require dotenv python module to be installed - included in `hrt_pipeline_env`):\n",
    "      ```text=\n",
    "      python download_from_db.py\n",
    "      ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Input JSON (config) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#example\n",
    "\n",
    "data_path = ['data_one.fits', 'data_two.fits', 'etc.fits...'] \n",
    "\n",
    "#can have as many files as you like, contintue the list\n",
    "\n",
    "\"\"\"\n",
    "IMPORTANT\n",
    "\n",
    "- files will be procssed with the same flat, dark\n",
    "- must have the same continuum position, pmp temp etc - checks will be run, and pipeline will exit if they fail\n",
    "- if data is a limb image, the limb in the FOV must be known - ie N, S, E, W etc. before processing\n",
    "\"\"\"\n",
    "\n",
    "dir_data_path = '/path/to/your/data/folder'\n",
    "data = [dir_data_path + i for i in data_path]\n",
    "\n",
    "flat_path = '/path/to/your/flat.fits'\n",
    "dark_path = '/path/to/your/dark.fits'\n",
    "\n",
    "input_dict = {\n",
    "\n",
    "    #input data\n",
    "    'data_f' : data,                            #hrt pipeline allows multiple files at once to be processed \n",
    "    'flat_f' : flat_path,\n",
    "    'dark_f' : dark_path,\n",
    "    \n",
    "    #input/output type + scaling\n",
    "    'L1_input' : False,                         #ignore - in development\n",
    "    'L1_8_generate': False,                     #ignore - in development\n",
    "    'scale_data' : True,                        #leave as True if L1 data\n",
    "    'accum_scaling' : True,                     #leave as True if L1 data\n",
    "    'bit_conversion' : True,                    #leave as True if L1 data\n",
    "    \n",
    "    #reduction\n",
    "    'dark_c' : True,                            #apply dark field correction\n",
    "    'flat_c' : True,                            #apply flat field correction\n",
    "    'norm_f' : True,                            #normalise the flats before used (DEFAULT: True)\n",
    "    'clean_f' : True,                           #clean the flat fields with unsharp masking\n",
    "    'sigma' : 59,                               #unsharp masking gaussian width\n",
    "    'clean_mode' : \"V\",                         #options 'QUV', 'UV', 'V' for the unsharp masking\n",
    "    'flat_states' : 24,                         #options 24 (DEFAULT), 4 (one each pol state), 6 (one each wavelength), \n",
    "    'prefilter_f': None,                        #provide the path for the prefilter .fits file\n",
    "    'fs_c' : True,                              #apply the field stop\n",
    "    'limb' : None,                               #for limb images - must know what limb in FOV: 'N','E','W','S'\n",
    "    'demod' : True,                             #demodulate to create the stokes maps\n",
    "    'norm_stokes' : True,                       #normalise the stokes maps to I_continuum\n",
    "    'ItoQUV' : False,                           #apply I-> Q,U,V cross talk correction\n",
    "    'ghost_c' : False,                          #if True, excludes ghost region for ItoQUV ctalk calculation \n",
    "    'rte' : False,                              #options: RTE', 'CE' (classical estimates), 'CE+RTE'\n",
    "    'p_milos' : False,                          #DO NOT USE\n",
    "    'cmilos_fits': False,                       #use cmilos with .fits IO - 16% speed up\n",
    "    \n",
    "    #output dir/filenames\n",
    "    'out_dir' : None,                           #directory where you want the output files to go (string)\n",
    "    'out_stokes_file' : False,                  #if True, will save the final stokes array to fits file(s)\n",
    "    'out_stokes_filename' : None,               #if specific required otherwise will default to standard convention\n",
    "    'out_rte_filename' : None,                  #if specific required otherwise will default to standard convention\n",
    "    'config' : True,                            #if True, saves a copy of the input file with runtime in the output folder\n",
    "    'out_intermediate': False,                  #if True, save intermediate steps to fits files in the output folder (OUT_STOKES_FILE MUST BE SET TO TRUE)\n",
    "}\n",
    "\n",
    "#json.dump(input_dict, open(f\"./input_jsons/name_your_input_file.json\", \"w\")) #uncomment to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "PHI HRT data reduction software   \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Reading Data\n",
      "Input contains 1 scan(s)\n",
      "Dividing by number of accumulations: 20\n",
      "Continuum position at wave:  0\n",
      "This scan has been flipped in the Y axis to conform to orientation standards. \n",
      " File: /data/slam/home/sinjan/fits_files/solo_L1_phi-hrt-ilam_20210914T071515_V202110260809C_0149140401.fits\n",
      "All the scan(s) have the same dimension\n",
      "All the scan(s) have the same continuum wavelength position\n",
      "All the scan(s) have the same PMP Temperature Set Point: 50\n",
      "Data shape is (2048, 2048, 24, 1)\n",
      "All the scan(s) have the same IMGDIRX keyword: YES\n",
      "Data reshaped to:  (2048, 2048, 4, 6, 1)\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------ Load science data time: 0.597 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Reading Flats\n",
      "Dividing by number of accumulations: 150\n",
      "Flat field shape is (24, 2048, 2048)\n",
      "(2048, 2048, 4, 6)\n",
      "Continuum position at wave:  5\n",
      "The continuum position of the flat field is at 5 index position\n",
      "The flat field continuum position is not the same as the data, trying to correct.\n",
      "Flat PMP Temperature Set Point: 50\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------ Load flats time: 0.625 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Reading Darks                   \n",
      "Dividing by number of accumulations: 20\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------ Load darks time: 0.031 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Subtracting dark field\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      "------------- Dark Field correction time: 0.067 seconds \u001b[92m\n",
      "-------------------------------------------------------------- \u001b[92m\n",
      " \u001b[0m\n",
      "-->>>>>>> Cleaning flats with Unsharp Masking\n",
      "Using a constant demodulation matrix for a PMP TEMP of 50 deg\n",
      "Unsharp Masking V\n"
     ]
    }
   ],
   "source": [
    "#RUN the pipe\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, './src/')\n",
    "from hrt_pipe import phihrt_pipe\n",
    "\n",
    "#error with input file\n",
    "\n",
    "phihrt_pipe('./input_jsons/test_nb.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrt_pipeline_env",
   "language": "python",
   "name": "hrt_pipeline_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
